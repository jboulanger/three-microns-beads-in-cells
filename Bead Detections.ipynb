{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bead detection\n",
    "\n",
    "Detect $3\\mu m$ beads inside cells and measure intensity of the signal on the \n",
    "beads in all channels. The bead detection is done using normalized cross \n",
    "correlation and the cell segmentation is achieved using cellpose.\n",
    "\n",
    "Process all images from a nikon nd2 file.\n",
    "\n",
    "# Connecting to hex\n",
    "ssh <username>@<login node>\n",
    "\n",
    "# Start a jupyter notebook on the login node\n",
    "Don't run heavy computation here but instead use dask to create jobs.\n",
    "```bash\n",
    "# change to yout code folder\n",
    "cd ~/code\n",
    "#srun --partition gpu --gres=gpu:gtx1080ti -c 32 --pty bash -i\n",
    "#srun --partition cpu -c 112 --pty bash -i\n",
    "conda activate puroanalysis\n",
    "jupyter lab --no-browser --ip=0.0.0.0\n",
    "```\n",
    "copy link from the \"copy paste URLs\" into search bar (click on jupyter remote) and then select kernel\n",
    "\n",
    "Update the code from github using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a field of view\n",
    "Test on a single field of view and visually inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nd2\n",
    "import beadfinder\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input / output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source folder accessible? True\n",
      "Destination folder accessible? True\n"
     ]
    }
   ],
   "source": [
    "src_folder = Path('/cephfs2/mlaub/20230511 bSaporin/')\n",
    "dst_folder = Path('/cephfs2/jeromeb/userdata/mlaub/20230511 bSaporin/')\n",
    "\n",
    "print('Source folder accessible?', src_folder.exists())\n",
    "if dst_folder.exists() is False:\n",
    "    print('Creating destination folder.')\n",
    "    dst_folder.mkdir(parents=True)\n",
    "print('Destination folder accessible?', dst_folder.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all files and save list in destination folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = src_folder.glob('*.nd2')\n",
    "filelist = []\n",
    "for filepath in files:    \n",
    "    with nd2.ND2File(filepath) as f:                \n",
    "        if f.ndim==4:\n",
    "            filelist.append({'folder':filepath.parent,'name':filepath.name,'fov':0})\n",
    "        else:            \n",
    "            for k in range(f.shape[0]):\n",
    "                filelist.append({'folder':filepath.parent,'name':filepath.name,'fov':k})\n",
    "\n",
    "filelist = pd.DataFrame.from_records(filelist)\n",
    "\n",
    "filelist.to_csv(dst_folder/'filelist.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tasks\n",
    "results = [beadfinder.process_row(src_folder, dst_folder, row) for row in filelist.iloc]\n",
    "\n",
    "# concatenate all results in 1 data frame\n",
    "cells = pd.concat([c for c,_ in results[0]])\n",
    "beads = pd.concat([b for _,b in results[0]])\n",
    "\n",
    "# export the data to cs files\n",
    "cells.to_csv(dst_folder / 'cells.csv')\n",
    "beads.to_csv(dst_folder / 'beads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel processing\n",
    "\n",
    "Select one type of partition on the cluster by running one of the two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lmb/home/jeromeb/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37529 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## GPU nodes\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "cluster = SLURMCluster(\n",
    "     cores = 64,\n",
    "     memory = '32GB',\n",
    "     queue = 'gpu',\n",
    "     processes = 1,\n",
    "     local_directory = '$SLURM_SCRATCH_DIR',\n",
    "     shebang = '#!/usr/bin/env tcsh',\n",
    "     walltime = '10:00:00',\n",
    "     death_timeout = 150,\n",
    "     job_extra_directives=['--gres=gpu:4']\n",
    ")\n",
    "cluster.adapt(maximum_jobs=30)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lmb/home/jeromeb/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 44263 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CPU nodes\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "cluster = SLURMCluster(\n",
    "     cores = 32,\n",
    "     memory = '32GB',     \n",
    "     queue = 'cpu', \n",
    "     processes = 1,\n",
    "     local_directory = '$SLURM_SCRATCH_DIR',     \n",
    "     shebang = '#!/usr/bin/env tcsh',     \n",
    "     walltime = '10:00:00',\n",
    "     death_timeout = 150,\n",
    ")\n",
    "cluster.adapt(maximum_jobs=30)\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all the files in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tsk \u001b[38;5;241m=\u001b[39m [dask\u001b[38;5;241m.\u001b[39mdelayed(beadfinder\u001b[38;5;241m.\u001b[39mprocess_row)(src_folder, dst_folder, row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m filelist\u001b[38;5;241m.\u001b[39miloc]\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtsk\u001b[49m\u001b[43m)\u001b[49m   \n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/site-packages/dask/base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    597\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 599\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/client.py:3168\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3166\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3168\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/client.py:2328\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2327\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/utils.py:345\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/utils.py:408\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 408\u001b[0m         \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    411\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/utils.py:397\u001b[0m, in \u001b[0;36msync.<locals>.wait\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(timeout):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 397\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m         loop\u001b[38;5;241m.\u001b[39madd_callback(cancel)\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/imaging/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "# create tasks\n",
    "tsk = [dask.delayed(beadfinder.process_row)(src_folder, dst_folder, row) for row in filelist.iloc]\n",
    "\n",
    "# run the tasks\n",
    "results = dask.compute(tsk)\n",
    "\n",
    "# concatenate all results in 1 data frame\n",
    "cells = pd.concat([c for c,_ in results[0]])\n",
    "beads = pd.concat([b for _,b in results[0]])\n",
    "\n",
    "# export the data to cs files\n",
    "cells.to_csv(dst_folder / 'cells.csv')\n",
    "beads.to_csv(dst_folder / 'beads.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/cephfs2/mlaub/20230511 bSaporin/Slide1_A3.nd2'\n",
    "#/Users/mlaub/Desktop/iSIM Data/20231012 bSaporin z-fa-fmk/Slide1_A1.nd2'\n",
    "#filepath = '/cephfs2/mlaub/20230511 bSaporin/Slide1_A3.nd2'\n",
    "#filepath = '/home/'\n",
    "#filepath = '/Volumes/cephfs2/mlaub/20230511 bSaporin/Slide1_A3.nd2'\n",
    "\n",
    "fov = 5\n",
    "\n",
    "with nd2.ND2File(filepath) as f:\n",
    "    spacing = f.metadata.channels[0].volume.axesCalibration[::-1]\n",
    "    array = f.to_dask()\n",
    "    \n",
    "spacing[0] = spacing[0] * 0.6\n",
    "\n",
    "#img = nd2.imread(filepath, dask=True)\n",
    "\n",
    "#img = array[fov,:,:,0:1000,0:1000].compute()\n",
    "img = array[fov].compute()\n",
    "cells_df, beads_df, labels = beadfinder.process_img(img, spacing, cell_stitch_threshold=0.1)\n",
    "#show_beads(img, pixel_size, t2)\n",
    "\n",
    "#import tifffile\n",
    "#tifffile.imwrite(filepath.replace('.nd2', '_label.tif'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "beadfinder.show_beads(np.log(img[:,1]), spacing, beads_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = beadfinder.detect_spheres(img[:, 2], spacing, 3, 0.1, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers2 = beadfinder.detect_beads(img[:,2], spacing, 3, 0.1, 1.4, 1.33, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = beadfinder.create_sphere([30,100,100], spacing, 3, 0.1)\n",
    "plt.imshow(np.amax(tmp1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.amax(img[:,2,50:250,50:500],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.log(np.amax(img[:,2],0)))\n",
    "plt.plot(1/spacing[2]*centers[:,2],1/spacing[1] * centers[:,1], 'w.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.amax(img[:,0],0)))\n",
    "plt.scatter(beads_df[\"X\"] / spacing[1], beads_df[\"Y\"] / spacing[2],c=beads_df[\"Fraction_inside\"],cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(beads_df,x='Fraction_inside',y='Mean_intensity_ch3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of the bead being inside using the 4th channel\n",
    "The 4th channel should have lower intensity when inside the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "beads_df['inside'] = beads_df['Fraction_inside'] > 0.9\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "sns.scatterplot(beads_df,x='Fraction_inside',y='Mean_intensity_ch3',hue='inside')\n",
    "plt.subplot(122)\n",
    "sns.boxplot(beads_df,x='inside',y='Mean_intensity_ch3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "beads_df['inside'] = beads_df['Fraction_inside'] > 0.9\n",
    "tmp = pd.melt(beads_df,id_vars=['inside'], value_vars=[f'Mean_intensity_ch{k}' for k in range(4)])\n",
    "sns.boxplot(beads_df,x='inside',y='Mean_intensity_ch3')\n",
    "#sns.scatterplot(tmp[],x='inside',y='value')\n",
    "#sns.boxplot(pd.wide_to_long(beads_df,['Mean_intensity_ch{k}' for k in range(4)]), )\n",
    "#for k in range(4):\n",
    "#    plt.boxplot(beads_df['Fraction_inside']>0.5, beads_df[f'Mean_intensity_ch{k}'])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bead_props = beadfinder.labelprops(labels[1], img, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bead_props[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = [np.sum((labels[1]==b['label'])*(labels[0]>0)) / np.sum((labels[1]==b['label'])) for b in bead_props]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fraction, [b['mean intensity'][3] for b in bead_props],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.plot(x='Fraction_inside',y='Mean_intensity_ch3',kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = beadfinder.create_sphere([30,100,100], spacing, radius, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "spacing = [0.33,0.11,0.11]\n",
    "shape = [32,100,100]\n",
    "radius = [1.5,1.5]\n",
    "#g = np.meshgrid(*[np.arange(n) for n in shape], indexing=\"ij\")\n",
    "#d = np.sqrt(sum([((x - n / 2) * p) ** 2 for x, n, p in zip(g, shape, spacing)]))\n",
    "#b = np.exp(-0.5 * np.square(np.abs(d - radius) / thickness)) + 0.5 * (d < radius)\n",
    "plt.imshow(np.amax(img,2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.33/1.518, 0.2/0.3, 50/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.4/1.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.fft.fftfreq(256, 1)\n",
    "y = np.zeros(x.shape)\n",
    "y[np.abs(x)>1e-8] = j1(x[np.abs(x)>1e-8]) / (x[np.abs(x)>1e-8])\n",
    "plt.plot(np.real(np.fft.fft(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import j1\n",
    "shape = [32,512,512]\n",
    "spacing = [1,1,1]\n",
    "p = beadfinder.compute_pinhole_otf(shape,spacing, 12)\n",
    "plt.imshow(np.real(np.fft.fftshift(np.fft.fftn(p[0]))))\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.518/1.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.ndimage import maximum_filter\n",
    "crop = img[:-3,2,170:240,160:230].astype(float)\n",
    "#crop = img[:,2,220:350,100:200].astype(float)\n",
    "shape = crop.shape\n",
    "spacing = [0.3*0.6,0.11,0.11]\n",
    "\n",
    "\n",
    "#b = beadfinder.create_sphere(shape, spacing, 1.5, 0.5)\n",
    "bhat = beadfinder.create_confocal_bead(shape, spacing, 3, 0.5, 1.4, 1.33, 0.5, 0.5, 0.5, 1)\n",
    "b = np.maximum(0,np.real(np.fft.fftn(bhat)))\n",
    "xc0 = beadfinder.normzxcorr(b,crop)\n",
    "#s1 = np.sqrt(np.real(np.fft.ifftn(np.conj(bhat)*bhat)))\n",
    "#s2 = np.sqrt(np.real(np.fft.ifftn(np.conj(np.fft.fftn(crop))*np.fft.fftn(crop))))\n",
    "#xc0 = np.real(np.fft.ifftn(np.conj(bhat)*np.fft.fftn(crop-100)))\n",
    "#xc0 = xc0 \n",
    "\n",
    "\n",
    "def wiener(f,y,s):    \n",
    "    return ftconv(np.conj(f) / (s + np.abs(f)**2), y)\n",
    "\n",
    "xc1 = wiener(bhat,crop,0.01)\n",
    "\n",
    "def ftconv(f,x):\n",
    "    return np.real(np.fft.ifftn(f*np.fft.fftn(x)))\n",
    "\n",
    "def deconvloc(f,y,s,niter):    \n",
    "    x = wiener(f,y,0.01)\n",
    "    for _ in range(niter):\n",
    "        x = x * ftconv(np.conj(f), crop / np.maximum(0.1, ftconv(f, x)))\n",
    "        x = np.maximum(0.0, x - s*x.max())\n",
    "    return x\n",
    "\n",
    "xc2 = deconvloc(bhat, crop, 0.001, 30)\n",
    "\n",
    "footprint = [2 * 1.5 / n for n in spacing]\n",
    "zyx = np.argwhere(\n",
    "    np.logical_and(xc2 > xc2.max() * 0.2, xc2 == maximum_filter(xc2, footprint))\n",
    ").astype(float)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(241)\n",
    "plt.imshow(np.log(1e-3+np.fft.fftshift(b[:,0,:])))\n",
    "plt.subplot(242)\n",
    "plt.imshow(np.log(crop[:,shape[1]//2,:]),cmap='Greens')\n",
    "plt.imshow(np.log(1e-3+np.fft.fftshift(b[:,0,:])),cmap='Reds',alpha=0.6)\n",
    "plt.subplot(243)\n",
    "plt.imshow(np.amax(crop,0))\n",
    "plt.subplot(244)\n",
    "plt.imshow(np.amax(xc0,0))\n",
    "plt.subplot(245)\n",
    "plt.imshow(np.amax(xc1,0))\n",
    "plt.subplot(246)\n",
    "plt.imshow(np.amax(xc2,0))\n",
    "plt.plot(zyx[:,2],zyx[:,1],'ro')\n",
    "#plt.imshow(np.abs(xc[25]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(crop)\n",
    "viewer.add_image(np.abs(xc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Expected bead volume is {(4/3*3.14156*radius**3)}')\n",
    "t2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all field of view\n",
    "We loop over the field of view to process all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/cephfs2/mlaub/Example images/A3.nd2'\n",
    "radius = 1.5\n",
    "pixel_size = [0.3,0.11,0.11]\n",
    "img = nd2.imread(filepath, dask=True)\n",
    "cells = []\n",
    "beads = []\n",
    "for k, pos in enumerate(img):\n",
    "    C,B,label = process_img(pos.compute(), pixel_size, radius)\n",
    "    # add the index of the field of view\n",
    "    C['FOV'] = k\n",
    "    B['FOV'] = k\n",
    "    cells.append(C)\n",
    "    beads.append(B)\n",
    "\n",
    "beads = pd.concat(beads)\n",
    "cells = pd.concat(cells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing on the HPC cluster\n",
    "Connect to hex, activate the environment and start jupyter from hex:\n",
    "```\n",
    "ssh hex\n",
    "conda activate imaging\n",
    "jupyter lab --no-browser --ip=0.0.0.0\n",
    "```\n",
    "Finally, connect to the remote kernel from visual code. We use now dask to distribute the computing across the nodes of the cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, progress\n",
    "import dask\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "     cores=16,\n",
    "     memory='32GB',\n",
    "     processes = 1,\n",
    "     queue = 'cpu',   \n",
    "     local_directory='$SLURM_SCRATCH_DIR',\n",
    "     death_timeout=150,\n",
    "     shebang='#!/usr/bin/env tcsh',     \n",
    "     walltime='10:00:00',\n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return x+1\n",
    "tsk = [dask.delayed(fun)(x)  for x in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(10)\n",
    "#dask.compute(tsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def delayed_process_img(img, pixel_size, radius, fov_idx):\n",
    "    try :\n",
    "        C, B, labels = process_img(img, pixel_size, radius)\n",
    "        C['FOV'] = fov_idx\n",
    "        B['FOV'] = fov_idx\n",
    "        return C, B\n",
    "    except :\n",
    "        return None, None\n",
    "\n",
    "filepath = '/cephfs2/mlaub/20230511 bSaporin/Slide1_B3.nd2'\n",
    "radius = 1.5\n",
    "pixel_size = [0.3,0.11,0.11]\n",
    "img = nd2.imread(filepath, dask=True)\n",
    "cluster.scale(len(img))\n",
    "tsk = [delayed_process_img(pos, pixel_size, radius, idx) for idx,pos in enumerate(img)]\n",
    "result = dask.compute(tsk)\n",
    "cluster.scale(0) # this frees the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = pd.concat([r[0] for r in result[0] ])\n",
    "beads = pd.concat([r[1] for r in result[0] ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the results\n",
    "Export the results as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next to the file\n",
    "beads.to_csv(filepath.replace('.nd2','_beads.csv'))\n",
    "cells.to_csv(filepath.replace('.nd2','_cells.csv'))\n",
    "# locally\n",
    "#beads.to_csv('beads.csv')\n",
    "#cells.to_csv('cells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph\n",
    "Get insight from the results by making a figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "beads = pd.read_csv('beads.csv')\n",
    "beads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "c1 = 'Mean_intensity_ch1'\n",
    "c2 = 'Mean_intensity_ch2'\n",
    "inside = beads['Fraction_inside'] > 0.75\n",
    "x = np.sqrt(beads[c1][inside])\n",
    "y = np.sqrt(beads[c2][inside])\n",
    "X,Y = np.mgrid[x.min():x.max():100j, y.min():y.max():100j]\n",
    "kernel = stats.gaussian_kde(np.vstack([x,y]))\n",
    "Z = kernel(np.vstack([X.ravel(),Y.ravel()])).reshape(X.shape)\n",
    "#plt.imshow(np.rot90(Z),extent=[x.min(),x.max(),y.min(),y.max()])\n",
    "plt.contour(X,Y,Z)\n",
    "plt.plot(x,y,'k.',ms=5,alpha=0.1)\n",
    "plt.xlabel(c1)\n",
    "plt.ylabel(c2)\n",
    "plt.title('Intensity of beads inside cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(beads['Volume'])\n",
    "plt.xlabel('Volume [$\\mu m^3$]')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of the volume of the beads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = '/cephfs2/mlaub/20230511 bSaporin/Slide1_A3.nd2'\n",
    "filepath = '/Volumes/cephfs2/mlaub/20230511 bSaporin/Slide1_A3.nd2'\n",
    "tbl_beads = pd.read_csv(filepath.replace('.nd2','_beads.csv'))\n",
    "filepath = '/Users/mlaub/Desktop/Slide1_A3.nd2'\n",
    "\n",
    "import nd2\n",
    "radius = 1.5\n",
    "pixel_size = [0.3,0.11,0.11]\n",
    "img = nd2.imread(filepath, dask=True)\n",
    "fov = 1\n",
    "img = img[fov,:,:,0:500,0:500].compute()\n",
    "print(img.shape)\n",
    "print(len(tbl_beads))\n",
    "tbl_beads = tbl_beads[tbl_beads['FOV']==fov]\n",
    "print(len(tbl_beads))\n",
    "#tbl_beads = tbl_beads.iloc[0:10]\n",
    "\n",
    "tmp  = np.squeeze(img[:,2,:,:])\n",
    "\n",
    "beads = bead_control(tmp, pixel_size, tbl_beads, 0.5)\n",
    "\n",
    "plt.imshow(np.amax(tmp,0),cmap='Greens')\n",
    "plt.imshow(np.amax(beads,0),cmap='Reds')\n",
    "\n",
    "\n",
    "#import napari\n",
    "#viewer = napari.view_image(img,scale=pixel_size,depiction='volume',gamma=0.5)\n",
    "#viewer.add_image(beads,contrast_limits=[0.1,0.5],scale=pixel_size,colormap='red',depiction='volume')\n",
    "#colors = np.random.rand(len(centers[I<250]), 3)\n",
    "#viewer.add_points(centers[I<250],size=3,shading='spherical',edge_width=0,face_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.amax(tmp,0),cmap='Greens')\n",
    "plt.imshow(np.amax(beads,0),cmap='Reds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "imaging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
