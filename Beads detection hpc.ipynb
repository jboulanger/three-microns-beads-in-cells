{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lmb/home/jeromeb/code/three-microns-beads-in-cells\n"
     ]
    }
   ],
   "source": [
    "cd code/three-microns-beads-in-cells/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beadfinder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source folder accessible? True\n",
      "Destination folder accessible? True\n"
     ]
    }
   ],
   "source": [
    "bf = beadfinder.BeadFinder('config1.yml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU nodes\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "cluster = SLURMCluster(\n",
    "     cores = 64,\n",
    "     memory = '32GB',\n",
    "     queue = 'gpu',\n",
    "     processes = 1,\n",
    "     local_directory = '$SLURM_SCRATCH_DIR',\n",
    "     shebang = '#!/usr/bin/env tcsh',\n",
    "     walltime = '10:00:00',\n",
    "     death_timeout = 150,\n",
    "     job_extra_directives=['--gres=gpu:4']\n",
    ")\n",
    "cluster.adapt(maximum_jobs=30)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lmb/home/jeromeb/miniconda3/envs/imaging/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40547 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CPU nodes\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "cluster = SLURMCluster(\n",
    "     cores = 32,\n",
    "     memory = '32GB',     \n",
    "     queue = 'cpu', \n",
    "     processes = 1,\n",
    "     local_directory = '$SLURM_SCRATCH_DIR',     \n",
    "     shebang = '#!/usr/bin/env tcsh',     \n",
    "     walltime = '10:00:00',\n",
    "     death_timeout = 150,\n",
    ")\n",
    "cluster.adapt(maximum_jobs=30)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "imaging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
